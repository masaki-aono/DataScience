{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10700 total articles\n",
      "7713 training data\n",
      "2987 testing data\n",
      "55  categories\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'cocoa', 'coffee', 'copper', 'corn', 'cotton', 'cpi', 'crude', 'dlr', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'hog', 'housing', 'interest', 'ipi', 'iron-steel', 'jobs', 'lead', 'livestock', 'meal-feed', 'money-fx', 'money-supply', 'nat-gas', 'oilseed', 'orange', 'palm-oil', 'pet-chem', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus.reader import *\n",
    "\n",
    "# Loading the corpus\n",
    "ma_reuters = LazyCorpusLoader(\n",
    "    'ma_reuters', CategorizedPlaintextCorpusReader, '(training|test).*',\n",
    "    cat_file='cats.txt', encoding='ISO-8859-2')\n",
    "\n",
    "# Load MA_Reuters\n",
    "documents = ma_reuters.fileids()\n",
    "print (str(len(documents)) + \" total articles\")\n",
    "# extracting training and testing data (document ID)\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "print (str(len(train_docs_id)) + \" training data\")\n",
    "print (str(len(test_docs_id)) + \" testing data\")\n",
    "# Training and testing data\n",
    "train_docs = [ma_reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [ma_reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    " \n",
    "# print the total number of categories\n",
    "categories = ma_reuters.categories()\n",
    "num_categories = len(categories)\n",
    "print (num_categories, \" categories\")\n",
    "print (categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([ma_reuters.categories(doc_id) for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([ma_reuters.categories(doc_id) for doc_id in test_docs_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/Users/naoki/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load('apnews_dbow/doc2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vector = [model.infer_vector(doc) for doc in train_docs]\n",
    "test_vector = [model.infer_vector(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard coef: 0.501\n",
      "Hamming Loss: 0.015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "# multi-class, multi-label classification and prediction\n",
    "OVR_classifier = OneVsRestClassifier(LinearSVC(random_state=41)) \n",
    "OVR_classifier.fit(train_vector, train_labels)\n",
    "OVR_predictions = OVR_classifier.predict(test_vector)\n",
    "# Evaluation\n",
    "import numpy as np\n",
    "# Jaccard coefficient\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "#print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, OVR_predictions, average='samples'),3))\n",
    "print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, OVR_predictions),3))\n",
    "\n",
    "# Hamming Loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "print (\"Hamming Loss:\",np.round(hamming_loss(test_labels, OVR_predictions),3))\n",
    "#test_pred = rf_ma_reuters.predict(test_docs)\n",
    "#print(classification_report(test_labels, test_pred, target_names=categories, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:acq\n",
      "  testing document dimension： 719\n",
      "  Jaccard coef: 0.665\n",
      "  Hamming Loss: 0.009\n",
      "category:alum\n",
      "  testing document dimension： 23\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.03\n",
      "category:barley\n",
      "  testing document dimension： 14\n",
      "  Jaccard coef: 0.02\n",
      "  Hamming Loss: 0.084\n",
      "category:bop\n",
      "  testing document dimension： 30\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.038\n",
      "category:carcass\n",
      "  testing document dimension： 18\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.055\n",
      "category:cocoa\n",
      "  testing document dimension： 18\n",
      "  Jaccard coef: 0.028\n",
      "  Hamming Loss: 0.023\n",
      "category:coffee\n",
      "  testing document dimension： 28\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.025\n",
      "category:copper\n",
      "  testing document dimension： 18\n",
      "  Jaccard coef: 0.019\n",
      "  Hamming Loss: 0.03\n",
      "category:corn\n",
      "  testing document dimension： 56\n",
      "  Jaccard coef: 0.029\n",
      "  Hamming Loss: 0.073\n",
      "category:cotton\n",
      "  testing document dimension： 20\n",
      "  Jaccard coef: 0.004\n",
      "  Hamming Loss: 0.08\n",
      "category:cpi\n",
      "  testing document dimension： 28\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.034\n",
      "category:crude\n",
      "  testing document dimension： 189\n",
      "  Jaccard coef: 0.011\n",
      "  Hamming Loss: 0.028\n",
      "category:dlr\n",
      "  testing document dimension： 44\n",
      "  Jaccard coef: 0.102\n",
      "  Hamming Loss: 0.04\n",
      "category:earn\n",
      "  testing document dimension： 1087\n",
      "  Jaccard coef: 0.912\n",
      "  Hamming Loss: 0.002\n",
      "category:fuel\n",
      "  testing document dimension： 10\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.027\n",
      "category:gas\n",
      "  testing document dimension： 17\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.032\n",
      "category:gnp\n",
      "  testing document dimension： 35\n",
      "  Jaccard coef: 0.048\n",
      "  Hamming Loss: 0.036\n",
      "category:gold\n",
      "  testing document dimension： 30\n",
      "  Jaccard coef: 0.017\n",
      "  Hamming Loss: 0.033\n",
      "category:grain\n",
      "  testing document dimension： 149\n",
      "  Jaccard coef: 0.038\n",
      "  Hamming Loss: 0.055\n",
      "category:hog\n",
      "  testing document dimension： 6\n",
      "  Jaccard coef: 0.083\n",
      "  Hamming Loss: 0.036\n",
      "category:housing\n",
      "  testing document dimension： 4\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.027\n",
      "category:interest\n",
      "  testing document dimension： 131\n",
      "  Jaccard coef: 0.099\n",
      "  Hamming Loss: 0.026\n",
      "category:ipi\n",
      "  testing document dimension： 12\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.023\n",
      "category:iron-steel\n",
      "  testing document dimension： 14\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.03\n",
      "category:jobs\n",
      "  testing document dimension： 21\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.035\n",
      "category:lead\n",
      "  testing document dimension： 14\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.043\n",
      "category:livestock\n",
      "  testing document dimension： 24\n",
      "  Jaccard coef: 0.021\n",
      "  Hamming Loss: 0.049\n",
      "category:meal-feed\n",
      "  testing document dimension： 19\n",
      "  Jaccard coef: 0.02\n",
      "  Hamming Loss: 0.106\n",
      "category:money-fx\n",
      "  testing document dimension： 179\n",
      "  Jaccard coef: 0.176\n",
      "  Hamming Loss: 0.025\n",
      "category:money-supply\n",
      "  testing document dimension： 34\n",
      "  Jaccard coef: 0.066\n",
      "  Hamming Loss: 0.024\n",
      "category:nat-gas\n",
      "  testing document dimension： 30\n",
      "  Jaccard coef: 0.072\n",
      "  Hamming Loss: 0.035\n",
      "category:oilseed\n",
      "  testing document dimension： 47\n",
      "  Jaccard coef: 0.013\n",
      "  Hamming Loss: 0.085\n",
      "category:orange\n",
      "  testing document dimension： 11\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.03\n",
      "category:palm-oil\n",
      "  testing document dimension： 10\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.056\n",
      "category:pet-chem\n",
      "  testing document dimension： 12\n",
      "  Jaccard coef: 0.125\n",
      "  Hamming Loss: 0.033\n",
      "category:rapeseed\n",
      "  testing document dimension： 9\n",
      "  Jaccard coef: 0.019\n",
      "  Hamming Loss: 0.071\n",
      "category:reserves\n",
      "  testing document dimension： 18\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.026\n",
      "category:retail\n",
      "  testing document dimension： 2\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.055\n",
      "category:rice\n",
      "  testing document dimension： 24\n",
      "  Jaccard coef: 0.008\n",
      "  Hamming Loss: 0.077\n",
      "category:rubber\n",
      "  testing document dimension： 12\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.038\n",
      "category:ship\n",
      "  testing document dimension： 89\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.032\n",
      "category:silver\n",
      "  testing document dimension： 8\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.057\n",
      "category:sorghum\n",
      "  testing document dimension： 10\n",
      "  Jaccard coef: 0.008\n",
      "  Hamming Loss: 0.124\n",
      "category:soy-meal\n",
      "  testing document dimension： 13\n",
      "  Jaccard coef: 0.023\n",
      "  Hamming Loss: 0.126\n",
      "category:soy-oil\n",
      "  testing document dimension： 11\n",
      "  Jaccard coef: 0.03\n",
      "  Hamming Loss: 0.124\n",
      "category:soybean\n",
      "  testing document dimension： 33\n",
      "  Jaccard coef: 0.017\n",
      "  Hamming Loss: 0.092\n",
      "category:strategic-metal\n",
      "  testing document dimension： 11\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.033\n",
      "category:sugar\n",
      "  testing document dimension： 36\n",
      "  Jaccard coef: 0.005\n",
      "  Hamming Loss: 0.033\n",
      "category:tin\n",
      "  testing document dimension： 12\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.032\n",
      "category:trade\n",
      "  testing document dimension： 117\n",
      "  Jaccard coef: 0.024\n",
      "  Hamming Loss: 0.03\n",
      "category:veg-oil\n",
      "  testing document dimension： 37\n",
      "  Jaccard coef: 0.013\n",
      "  Hamming Loss: 0.064\n",
      "category:wheat\n",
      "  testing document dimension： 71\n",
      "  Jaccard coef: 0.044\n",
      "  Hamming Loss: 0.063\n",
      "category:wpi\n",
      "  testing document dimension： 10\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.024\n",
      "category:yen\n",
      "  testing document dimension： 14\n",
      "  Jaccard coef: 0.042\n",
      "  Hamming Loss: 0.042\n",
      "category:zinc\n",
      "  testing document dimension： 13\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.041\n"
     ]
    }
   ],
   "source": [
    "Jmax = 0.500001\n",
    "Jmax_category = \"\"\n",
    "Jmin_category = \"\"\n",
    "Jmin = 0.5\n",
    "for c in categories:\n",
    "    category_docs_c = ma_reuters.fileids(str(c));\n",
    "    print(\"category:\" + c)\n",
    "    test_docs_id_c = list(filter(lambda doc: doc.startswith(\"test\"), category_docs_c))\n",
    "    test_docs_c = [ma_reuters.raw(doc_id) for doc_id in test_docs_id_c]\n",
    "    # transform\n",
    "    vectorised_test_document_c = [model.infer_vector(doc) for doc in test_docs_c]\n",
    "    print(\"  testing document dimension：\",len(vectorised_test_document_c))\n",
    "    OVR_predictions_c = OVR_classifier.predict(vectorised_test_document_c)\n",
    "    test_label_c = mlb.transform([ma_reuters.categories(doc_id) for doc_id in test_docs_id_c])\n",
    "    JacCoef = np.round(jaccard_similarity_score(test_label_c, OVR_predictions_c),3)\n",
    "    HamLoss = np.round(hamming_loss(test_label_c, OVR_predictions_c),3)\n",
    "    print (\"  Jaccard coef:\",JacCoef)\n",
    "    print (\"  Hamming Loss:\",HamLoss)\n",
    "    if(JacCoef > Jmax):\n",
    "        Jmax = JacCoef\n",
    "        Jmax_category = c\n",
    "    if(JacCoef < Jmin):\n",
    "        Jmin = JacCoef\n",
    "        Jmin_category = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Jaccard score is earn: 0.912\n",
      "Lowest Jaccard score is alum: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest Jaccard score is \" + Jmax_category + \": \" + str(Jmax))\n",
    "print(\"Lowest Jaccard score is \" + Jmin_category + \": \" + str(Jmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 1000,max_depth=5) \n",
    "forest = forest.fit(train_vector, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard coef: 0.495\n",
      "Hamming Loss: 0.014\n"
     ]
    }
   ],
   "source": [
    "forest_predictions = forest.predict(test_vector)\n",
    "print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, forest_predictions),3))\n",
    "print (\"Hamming Loss:\",np.round(hamming_loss(test_labels, forest_predictions),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
