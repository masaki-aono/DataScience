{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10700 total articles\n",
      "7713 training data\n",
      "2987 testing data\n",
      "55  categories\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'cocoa', 'coffee', 'copper', 'corn', 'cotton', 'cpi', 'crude', 'dlr', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'hog', 'housing', 'interest', 'ipi', 'iron-steel', 'jobs', 'lead', 'livestock', 'meal-feed', 'money-fx', 'money-supply', 'nat-gas', 'oilseed', 'orange', 'palm-oil', 'pet-chem', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus.reader import *\n",
    "\n",
    "# Loading the corpus\n",
    "ma_reuters = LazyCorpusLoader(\n",
    "    'ma_reuters', CategorizedPlaintextCorpusReader, '(training|test).*',\n",
    "    cat_file='cats.txt', encoding='ISO-8859-2')\n",
    "\n",
    "# Load MA_Reuters\n",
    "documents = ma_reuters.fileids()\n",
    "print (str(len(documents)) + \" total articles\")\n",
    "# extracting training and testing data (document ID)\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "print (str(len(train_docs_id)) + \" training data\")\n",
    "print (str(len(test_docs_id)) + \" testing data\")\n",
    "# Training and testing data\n",
    "train_docs = [ma_reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [ma_reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    " \n",
    "# print the total number of categories\n",
    "categories = ma_reuters.categories()\n",
    "num_categories = len(categories)\n",
    "print (num_categories, \" categories\")\n",
    "print (categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERMAN INDUSTRIAL EMPLOYMENT SEEN STAGNATING\n",
      "  The number of workers employed in\n",
      "  the West German industrial sector stagnated in the last quarter\n",
      "  of 1986 as a 50,000 increase in overall employment benefited\n",
      "  only the services branch, the DIW economic institute said.\n",
      "      A DIW report added the general downturn in the economy\n",
      "  since last Autumn had had a negative effect on the willingness\n",
      "  of firms to take on workers. It referred to a marked downturn\n",
      "  in the number of workers taken on in the capital goods sector.\n",
      "      New orders for manufacturing industry goods have mostly\n",
      "  fallen or stagnated in recent months, but data for February\n",
      "  finally showed a reversal of the trend, with a 1.9 pct rise.\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# raw document example（'jobs category')\n",
    "# Documents in a category\n",
    "category_docs = ma_reuters.fileids(\"jobs\");\n",
    "document_id = category_docs[0] # The first document\n",
    "# print the inside document\n",
    "print (ma_reuters.raw(document_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted to TF-IF model\n",
      "training document dimension ： (7713, 26986)\n",
      "testing document dimension： (2987, 26986)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "import re # regular expression\n",
    " \n",
    "def tokenize(text): # returning tokens\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "\n",
    "    p = re.compile('[a-zA-Z]+')\n",
    "    filtered_tokens = list(filter (lambda token: p.match(token) and len(token) >= min_length, words))\n",
    "    return filtered_tokens\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
    "# fit_transform\n",
    "vectorised_train_documents = vectorizer.fit_transform(train_docs)\n",
    "# transform\n",
    "vectorised_test_documents = vectorizer.transform(test_docs)\n",
    "print(\"converted to TF-IF model\")\n",
    "print(\"training document dimension ：\",vectorised_train_documents.shape)\n",
    "print(\"testing document dimension：\",vectorised_test_documents.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard coef: 0.86\n",
      "Hamming Loss: 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([ma_reuters.categories(doc_id) for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([ma_reuters.categories(doc_id) for doc_id in test_docs_id])\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# multi-class, multi-label classification and prediction\n",
    "OVR_classifier = OneVsRestClassifier(LinearSVC(random_state=41)) \n",
    "OVR_classifier.fit(vectorised_train_documents, train_labels)\n",
    "OVR_predictions = OVR_classifier.predict(vectorised_test_documents)\n",
    "\n",
    "import numpy as np\n",
    "# Jaccard coefficient\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "#print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, OVR_predictions, average='samples'),3))\n",
    "print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, OVR_predictions),3))\n",
    "\n",
    "# Hamming Loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "print (\"Hamming Loss:\",np.round(hamming_loss(test_labels, OVR_predictions),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:acq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naoki/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  testing document dimension： (719, 26986)\n",
      "  Jaccard coef: 0.941\n",
      "  Hamming Loss: 0.002\n",
      "category:alum\n",
      "  testing document dimension： (23, 26986)\n",
      "  Jaccard coef: 0.467\n",
      "  Hamming Loss: 0.016\n",
      "category:barley\n",
      "  testing document dimension： (14, 26986)\n",
      "  Jaccard coef: 0.76\n",
      "  Hamming Loss: 0.038\n",
      "category:bop\n",
      "  testing document dimension： (30, 26986)\n",
      "  Jaccard coef: 0.603\n",
      "  Hamming Loss: 0.018\n",
      "category:carcass\n",
      "  testing document dimension： (18, 26986)\n",
      "  Jaccard coef: 0.427\n",
      "  Hamming Loss: 0.033\n",
      "category:cocoa\n",
      "  testing document dimension： (18, 26986)\n",
      "  Jaccard coef: 0.926\n",
      "  Hamming Loss: 0.002\n",
      "category:coffee\n",
      "  testing document dimension： (28, 26986)\n",
      "  Jaccard coef: 0.935\n",
      "  Hamming Loss: 0.004\n",
      "category:copper\n",
      "  testing document dimension： (18, 26986)\n",
      "  Jaccard coef: 0.75\n",
      "  Hamming Loss: 0.013\n",
      "category:corn\n",
      "  testing document dimension： (56, 26986)\n",
      "  Jaccard coef: 0.715\n",
      "  Hamming Loss: 0.032\n",
      "category:cotton\n",
      "  testing document dimension： (20, 26986)\n",
      "  Jaccard coef: 0.618\n",
      "  Hamming Loss: 0.054\n",
      "category:cpi\n",
      "  testing document dimension： (28, 26986)\n",
      "  Jaccard coef: 0.536\n",
      "  Hamming Loss: 0.021\n",
      "category:crude\n",
      "  testing document dimension： (189, 26986)\n",
      "  Jaccard coef: 0.81\n",
      "  Hamming Loss: 0.006\n",
      "category:dlr\n",
      "  testing document dimension： (44, 26986)\n",
      "  Jaccard coef: 0.731\n",
      "  Hamming Loss: 0.014\n",
      "category:earn\n",
      "  testing document dimension： (1087, 26986)\n",
      "  Jaccard coef: 0.976\n",
      "  Hamming Loss: 0.001\n",
      "category:fuel\n",
      "  testing document dimension： (10, 26986)\n",
      "  Jaccard coef: 0.25\n",
      "  Hamming Loss: 0.02\n",
      "category:gas\n",
      "  testing document dimension： (17, 26986)\n",
      "  Jaccard coef: 0.441\n",
      "  Hamming Loss: 0.014\n",
      "category:gnp\n",
      "  testing document dimension： (35, 26986)\n",
      "  Jaccard coef: 0.553\n",
      "  Hamming Loss: 0.021\n",
      "category:gold\n",
      "  testing document dimension： (30, 26986)\n",
      "  Jaccard coef: 0.672\n",
      "  Hamming Loss: 0.013\n",
      "category:grain\n",
      "  testing document dimension： (149, 26986)\n",
      "  Jaccard coef: 0.732\n",
      "  Hamming Loss: 0.022\n",
      "category:hog\n",
      "  testing document dimension： (6, 26986)\n",
      "  Jaccard coef: 0.472\n",
      "  Hamming Loss: 0.027\n",
      "category:housing\n",
      "  testing document dimension： (4, 26986)\n",
      "  Jaccard coef: 0.875\n",
      "  Hamming Loss: 0.005\n",
      "category:interest\n",
      "  testing document dimension： (131, 26986)\n",
      "  Jaccard coef: 0.663\n",
      "  Hamming Loss: 0.012\n",
      "category:ipi\n",
      "  testing document dimension： (12, 26986)\n",
      "  Jaccard coef: 0.833\n",
      "  Hamming Loss: 0.006\n",
      "category:iron-steel\n",
      "  testing document dimension： (14, 26986)\n",
      "  Jaccard coef: 0.679\n",
      "  Hamming Loss: 0.006\n",
      "category:jobs\n",
      "  testing document dimension： (21, 26986)\n",
      "  Jaccard coef: 0.659\n",
      "  Hamming Loss: 0.016\n",
      "category:lead\n",
      "  testing document dimension： (14, 26986)\n",
      "  Jaccard coef: 0.107\n",
      "  Hamming Loss: 0.034\n",
      "category:livestock\n",
      "  testing document dimension： (24, 26986)\n",
      "  Jaccard coef: 0.515\n",
      "  Hamming Loss: 0.028\n",
      "category:meal-feed\n",
      "  testing document dimension： (19, 26986)\n",
      "  Jaccard coef: 0.32\n",
      "  Hamming Loss: 0.084\n",
      "category:money-fx\n",
      "  testing document dimension： (179, 26986)\n",
      "  Jaccard coef: 0.649\n",
      "  Hamming Loss: 0.011\n",
      "category:money-supply\n",
      "  testing document dimension： (34, 26986)\n",
      "  Jaccard coef: 0.752\n",
      "  Hamming Loss: 0.01\n",
      "category:nat-gas\n",
      "  testing document dimension： (30, 26986)\n",
      "  Jaccard coef: 0.589\n",
      "  Hamming Loss: 0.015\n",
      "category:oilseed\n",
      "  testing document dimension： (47, 26986)\n",
      "  Jaccard coef: 0.563\n",
      "  Hamming Loss: 0.046\n",
      "category:orange\n",
      "  testing document dimension： (11, 26986)\n",
      "  Jaccard coef: 0.758\n",
      "  Hamming Loss: 0.01\n",
      "category:palm-oil\n",
      "  testing document dimension： (10, 26986)\n",
      "  Jaccard coef: 0.647\n",
      "  Hamming Loss: 0.025\n",
      "category:pet-chem\n",
      "  testing document dimension： (12, 26986)\n",
      "  Jaccard coef: 0.125\n",
      "  Hamming Loss: 0.026\n",
      "category:rapeseed\n",
      "  testing document dimension： (9, 26986)\n",
      "  Jaccard coef: 0.607\n",
      "  Hamming Loss: 0.04\n",
      "category:reserves\n",
      "  testing document dimension： (18, 26986)\n",
      "  Jaccard coef: 0.648\n",
      "  Hamming Loss: 0.013\n",
      "category:retail\n",
      "  testing document dimension： (2, 26986)\n",
      "  Jaccard coef: 0.625\n",
      "  Hamming Loss: 0.027\n",
      "category:rice\n",
      "  testing document dimension： (24, 26986)\n",
      "  Jaccard coef: 0.462\n",
      "  Hamming Loss: 0.052\n",
      "category:rubber\n",
      "  testing document dimension： (12, 26986)\n",
      "  Jaccard coef: 0.762\n",
      "  Hamming Loss: 0.017\n",
      "category:ship\n",
      "  testing document dimension： (89, 26986)\n",
      "  Jaccard coef: 0.704\n",
      "  Hamming Loss: 0.009\n",
      "category:silver\n",
      "  testing document dimension： (8, 26986)\n",
      "  Jaccard coef: 0.271\n",
      "  Hamming Loss: 0.041\n",
      "category:sorghum\n",
      "  testing document dimension： (10, 26986)\n",
      "  Jaccard coef: 0.411\n",
      "  Hamming Loss: 0.082\n",
      "category:soy-meal\n",
      "  testing document dimension： (13, 26986)\n",
      "  Jaccard coef: 0.356\n",
      "  Hamming Loss: 0.097\n",
      "category:soy-oil\n",
      "  testing document dimension： (11, 26986)\n",
      "  Jaccard coef: 0.237\n",
      "  Hamming Loss: 0.099\n",
      "category:soybean\n",
      "  testing document dimension： (33, 26986)\n",
      "  Jaccard coef: 0.561\n",
      "  Hamming Loss: 0.049\n",
      "category:strategic-metal\n",
      "  testing document dimension： (11, 26986)\n",
      "  Jaccard coef: 0.0\n",
      "  Hamming Loss: 0.031\n",
      "category:sugar\n",
      "  testing document dimension： (36, 26986)\n",
      "  Jaccard coef: 0.761\n",
      "  Hamming Loss: 0.015\n",
      "category:tin\n",
      "  testing document dimension： (12, 26986)\n",
      "  Jaccard coef: 0.616\n",
      "  Hamming Loss: 0.018\n",
      "category:trade\n",
      "  testing document dimension： (117, 26986)\n",
      "  Jaccard coef: 0.723\n",
      "  Hamming Loss: 0.012\n",
      "category:veg-oil\n",
      "  testing document dimension： (37, 26986)\n",
      "  Jaccard coef: 0.47\n",
      "  Hamming Loss: 0.047\n",
      "category:wheat\n",
      "  testing document dimension： (71, 26986)\n",
      "  Jaccard coef: 0.747\n",
      "  Hamming Loss: 0.024\n",
      "category:wpi\n",
      "  testing document dimension： (10, 26986)\n",
      "  Jaccard coef: 0.525\n",
      "  Hamming Loss: 0.013\n",
      "category:yen\n",
      "  testing document dimension： (14, 26986)\n",
      "  Jaccard coef: 0.305\n",
      "  Hamming Loss: 0.031\n",
      "category:zinc\n",
      "  testing document dimension： (13, 26986)\n",
      "  Jaccard coef: 0.385\n",
      "  Hamming Loss: 0.028\n"
     ]
    }
   ],
   "source": [
    "Jmax = 0.500001\n",
    "Jmax_category = \"\"\n",
    "Jmin_category = \"\"\n",
    "Jmin = 0.5\n",
    "for c in categories:\n",
    "    category_docs_c = ma_reuters.fileids(str(c));\n",
    "    print(\"category:\" + c)\n",
    "    test_docs_id_c = list(filter(lambda doc: doc.startswith(\"test\"), category_docs_c))\n",
    "    test_docs_c = [ma_reuters.raw(doc_id) for doc_id in test_docs_id_c]\n",
    "    # transform\n",
    "    vectorised_test_document_c = vectorizer.transform(test_docs_c)\n",
    "    print(\"  testing document dimension：\",vectorised_test_document_c.shape)\n",
    "    OVR_predictions_c = OVR_classifier.predict(vectorised_test_document_c)\n",
    "    test_label_c = mlb.transform([ma_reuters.categories(doc_id) for doc_id in test_docs_id_c])\n",
    "    JacCoef = np.round(jaccard_similarity_score(test_label_c, OVR_predictions_c),3)\n",
    "    HamLoss = np.round(hamming_loss(test_label_c, OVR_predictions_c),3)\n",
    "    print (\"  Jaccard coef:\",JacCoef)\n",
    "    print (\"  Hamming Loss:\",HamLoss)\n",
    "    if(JacCoef > Jmax):\n",
    "        Jmax = JacCoef\n",
    "        Jmax_category = c\n",
    "    if(JacCoef < Jmin):\n",
    "        Jmin = JacCoef\n",
    "        Jmin_category = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Jaccard score is earn: 0.976\n",
      "Lowest Jaccard score is strategic-metal: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest Jaccard score is \" + Jmax_category + \": \" + str(Jmax))\n",
    "print(\"Lowest Jaccard score is \" + Jmin_category + \": \" + str(Jmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn: 2877\n",
      "strategic-metal: 16\n"
     ]
    }
   ],
   "source": [
    "jmax_docs = ma_reuters.fileids(str(Jmax_category));\n",
    "jmin_docs = ma_reuters.fileids(str(Jmin_category));\n",
    "test_docs_id_jmax = list(filter(lambda doc: doc.startswith(\"train\"), jmax_docs))\n",
    "test_docs_id_jmin = list(filter(lambda doc: doc.startswith(\"train\"), jmin_docs))\n",
    "# print the inside document\n",
    "print (Jmax_category + \": \" + str(len(test_docs_id_jmax)))\n",
    "print (Jmin_category + \": \" + str(len(test_docs_id_jmin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit(vectorised_train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard coef: 0.679\n",
      "Hamming Loss: 0.009\n"
     ]
    }
   ],
   "source": [
    "forest_predictions = forest.predict(vectorised_test_documents)\n",
    "print (\"Jaccard coef:\",np.round(jaccard_similarity_score(test_labels, forest_predictions),3))\n",
    "print (\"Hamming Loss:\",np.round(hamming_loss(test_labels, forest_predictions),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
